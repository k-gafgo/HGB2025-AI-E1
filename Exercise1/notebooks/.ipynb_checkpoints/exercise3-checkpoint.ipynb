{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c26d0c6",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "## Part 3 - Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2583bc2d",
   "metadata": {},
   "source": [
    "### 0. Imports & Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import builtins  # <-- IMPORTANT\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    avg,\n",
    "    round as spark_round,   # Spark round ONLY for Columns\n",
    "    count,\n",
    "    col,\n",
    "    sum as _sum\n",
    ")\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"PostgresVsSparkBenchmark\")\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.7.2\")\n",
    "    .config(\"spark.eventLog.enabled\", \"true\")\n",
    "    .config(\"spark.eventLog.dir\", \"/tmp/spark-events\")\n",
    "    .config(\"spark.history.fs.logDirectory\", \"/tmp/spark-events\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\")\n",
    "    .config(\"spark.default.parallelism\", \"4\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a5a041",
   "metadata": {},
   "source": [
    "### 1. JDBC connection config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbc_url = \"jdbc:postgresql://postgres:5432/postgres\"\n",
    "jdbc_props = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7b852c",
   "metadata": {},
   "source": [
    "### 2. Load data from PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea9b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Loading people_big from PostgreSQL ===\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "df_big = spark.read.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"people_big\",\n",
    "    properties=jdbc_props\n",
    ")\n",
    "\n",
    "# Force materialization\n",
    "row_count = df_big.count()\n",
    "\n",
    "print(f\"Rows loaded: {row_count}\")\n",
    "print(\"Load time:\", builtins.round(time.time() - start, 2), \"seconds\")\n",
    "\n",
    "# Register temp view\n",
    "df_big.createOrReplaceTempView(\"people_big\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b1e61",
   "metadata": {},
   "source": [
    "### 3. Query (a): Simple aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed9b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Query (a): AVG salary per department ===\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "q_a = (\n",
    "    df_big\n",
    "    .groupBy(\"department\")\n",
    "    .agg(spark_round(avg(\"salary\"), 2).alias(\"avg_salary\"))\n",
    "    .orderBy(\"department\", ascending=False)\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "q_a.collect()\n",
    "q_a.show(truncate=False)\n",
    "print(\"Query (a) time:\", builtins.round(time.time() - start, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114b77c6",
   "metadata": {},
   "source": [
    "### 4. Query (b): Nested aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c276a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Query (b): Nested aggregation ===\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "q_b = spark.sql(\"\"\"\n",
    "SELECT country, AVG(avg_salary) AS avg_salary\n",
    "FROM (\n",
    "    SELECT country, department, AVG(salary) AS avg_salary\n",
    "    FROM people_big\n",
    "    GROUP BY country, department\n",
    ") sub\n",
    "GROUP BY country\n",
    "ORDER BY avg_salary DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "q_b.collect()\n",
    "q_b.show(truncate=False)\n",
    "print(\"Query (b) time:\", builtins.round(time.time() - start, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dfc836",
   "metadata": {},
   "source": [
    "### 5. Query (c): Sorting + Top-N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce41114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Query (c): Top 10 salaries ===\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "q_c = (\n",
    "    df_big\n",
    "    .orderBy(col(\"salary\").desc())\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "q_c.collect()\n",
    "q_c.show(truncate=False)\n",
    "print(\"Query (c) time:\", builtins.round(time.time() - start, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f199c15b",
   "metadata": {},
   "source": [
    "### 6. Query (d): Heavy self-join (COUNT only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e207e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Query (d): Heavy self-join COUNT (DANGEROUS) ===\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "q_d = (\n",
    "    df_big.alias(\"p1\")\n",
    "    .join(df_big.alias(\"p2\"), on=\"country\")\n",
    "    .count()\n",
    ")\n",
    "\n",
    "print(\"Join count:\", q_d)\n",
    "print(\"Query (d) time:\", builtins.round(time.time() - start, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87208e5c",
   "metadata": {},
   "source": [
    "### 7. Query (d-safe): Join-equivalent rewrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec08c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Query (d-safe): Join-equivalent rewrite ===\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "grouped = df_big.groupBy(\"country\").agg(count(\"*\").alias(\"cnt\"))\n",
    "\n",
    "q_d_safe = grouped.select(\n",
    "    _sum(col(\"cnt\") * col(\"cnt\")).alias(\"total_pairs\")\n",
    ")\n",
    "\n",
    "q_d_safe.collect()\n",
    "q_d_safe.show()\n",
    "print(\"Query (d-safe) time:\", builtins.round(time.time() - start, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bdd26b",
   "metadata": {},
   "source": [
    "### 8. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f425534",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
